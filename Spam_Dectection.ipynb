{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Spam Detection (5 Videos)\n",
    "## Abstract\n",
    "Try to detect spam comments on youtube videos. The dataset contains 5 videos with 5 different classes of comments.<br>\n",
    "Data Source: https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection<br>\n",
    "\n",
    "Data Set Information:<br>\n",
    "The table below lists the datasets, the YouTube video ID, the amount of samples in each class and the total number of samples per dataset.<br>\n",
    "\n",
    "| Dataset | YouTube ID | # Spam | # Ham | Total |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Psy | 9bZkp7q19f0 | 175 | 175 | 350 |\n",
    "| KatyPerry | CevxZvSJLk8 | 175 | 175 | 350 |\n",
    "| LMFAO | KQ6zr6kCPj8 | 236 | 202 | 438 |\n",
    "| Eminem | uelHwf8o7_U | 245 | 203 | 448 |\n",
    "| Shakira | pRpeEdMmmQ0 | 174 | 196 | 370 |\n",
    "\n",
    "First, we will only use the first video (Psy) to train the model. Then, we will use all the videos to train the model. Using Bag of Words (BoW) and Random Froset (RF) to train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>z13th1q4yzihf1bll23qxzpjeujterydj</td>\n",
       "      <td>Carmen Racasanu</td>\n",
       "      <td>2014-11-14T13:27:52</td>\n",
       "      <td>How can this have 2 billion views when there's...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>z13fcn1wfpb5e51xe04chdxakpzgchyaxzo0k</td>\n",
       "      <td>diego mogrovejo</td>\n",
       "      <td>2014-11-14T13:28:08</td>\n",
       "      <td>I don't now why I'm watching this in 2014﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>z130zd5b3titudkoe04ccbeohojxuzppvbg</td>\n",
       "      <td>BlueYetiPlayz -Call Of Duty and More</td>\n",
       "      <td>2015-05-23T13:04:32</td>\n",
       "      <td>subscribe to me for call of duty vids and give...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>z12he50arvrkivl5u04cctawgxzkjfsjcc4</td>\n",
       "      <td>Photo Editor</td>\n",
       "      <td>2015-06-05T14:14:48</td>\n",
       "      <td>hi guys please my android photo editor downloa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>z13vhvu54u3ewpp5h04ccb4zuoardrmjlyk0k</td>\n",
       "      <td>Ray Benich</td>\n",
       "      <td>2015-06-05T18:05:16</td>\n",
       "      <td>The first billion viewed this because they tho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                COMMENT_ID  \\\n",
       "345      z13th1q4yzihf1bll23qxzpjeujterydj   \n",
       "346  z13fcn1wfpb5e51xe04chdxakpzgchyaxzo0k   \n",
       "347    z130zd5b3titudkoe04ccbeohojxuzppvbg   \n",
       "348    z12he50arvrkivl5u04cctawgxzkjfsjcc4   \n",
       "349  z13vhvu54u3ewpp5h04ccb4zuoardrmjlyk0k   \n",
       "\n",
       "                                   AUTHOR                 DATE  \\\n",
       "345                       Carmen Racasanu  2014-11-14T13:27:52   \n",
       "346                       diego mogrovejo  2014-11-14T13:28:08   \n",
       "347  BlueYetiPlayz -Call Of Duty and More  2015-05-23T13:04:32   \n",
       "348                          Photo Editor  2015-06-05T14:14:48   \n",
       "349                            Ray Benich  2015-06-05T18:05:16   \n",
       "\n",
       "                                               CONTENT  CLASS  \n",
       "345  How can this have 2 billion views when there's...      0  \n",
       "346         I don't now why I'm watching this in 2014﻿      0  \n",
       "347  subscribe to me for call of duty vids and give...      1  \n",
       "348  hi guys please my android photo editor downloa...      1  \n",
       "349  The first billion viewed this because they tho...      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in The Psy file, and display the tail\n",
    "df_psy = pd.read_csv('../Intro_AI_Project_3/Youtube01-Psy.csv')\n",
    "df_psy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 5)\n"
     ]
    }
   ],
   "source": [
    "# find number of rows and columns\n",
    "print(df_psy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 350 rows and 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    175\n",
       "0    175\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of 0, 1 in CLASS\n",
    "df_psy.CLASS.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you compare the commnet content and class, you can find out class 0 equal to not spam and class 1 equal to spam. In psy.csv file, there are 175 rows spam and 175 rows not spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Bag of Words function and create an instance\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the comments in one step\n",
    "dvec = vectorizer.fit_transform(df_psy['CONTENT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<350x1418 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4354 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of sparse matrix is 350x1418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first billion viewed this because they thought it was really cool, the  other billion and a half came to see how stupid the first billion were...﻿\n"
     ]
    }
   ],
   "source": [
    "# print out 349th comment\n",
    "print(df_psy['CONTENT'][349])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'first',\n",
       " 'billion',\n",
       " 'viewed',\n",
       " 'this',\n",
       " 'because',\n",
       " 'they',\n",
       " 'thought',\n",
       " 'it',\n",
       " 'was',\n",
       " 'really',\n",
       " 'cool',\n",
       " 'the',\n",
       " 'other',\n",
       " 'billion',\n",
       " 'and',\n",
       " 'half',\n",
       " 'came',\n",
       " 'to',\n",
       " 'see',\n",
       " 'how',\n",
       " 'stupid',\n",
       " 'the',\n",
       " 'first',\n",
       " 'billion',\n",
       " 'were']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using vectorizer.build_analyzer() display\n",
    "# the breakdown of the 349th comment in to a “bag of words”\n",
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(df_psy['CONTENT'][349])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tonyw\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '02',\n",
       " '034',\n",
       " '05',\n",
       " '08',\n",
       " '10',\n",
       " '100',\n",
       " '100000415527985',\n",
       " '10200253113705769',\n",
       " '1030',\n",
       " '1073741828',\n",
       " '11',\n",
       " '1111',\n",
       " '112720997191206369631',\n",
       " '12',\n",
       " '123',\n",
       " '124',\n",
       " '124923004',\n",
       " '126',\n",
       " '127',\n",
       " '13017194',\n",
       " '131338190916',\n",
       " '1340488',\n",
       " '1340489',\n",
       " '1340490',\n",
       " '1340491',\n",
       " '1340492',\n",
       " '1340493',\n",
       " '1340494',\n",
       " '1340499',\n",
       " '1340500',\n",
       " '1340502',\n",
       " '1340503',\n",
       " '1340504',\n",
       " '1340517',\n",
       " '1340518',\n",
       " '1340519',\n",
       " '1340520',\n",
       " '1340521',\n",
       " '1340522',\n",
       " '1340523',\n",
       " '1340524',\n",
       " '134470083389909',\n",
       " '1415297812',\n",
       " '1495323920744243',\n",
       " '1496241863981208',\n",
       " '1496273723978022',\n",
       " '1498561870415874',\n",
       " '161620527267482',\n",
       " '171183229277',\n",
       " '19',\n",
       " '19924',\n",
       " '1firo',\n",
       " '1m',\n",
       " '20',\n",
       " '2009',\n",
       " '2012',\n",
       " '2012bitches',\n",
       " '2013',\n",
       " '2014',\n",
       " '201470069872822',\n",
       " '2015',\n",
       " '2017',\n",
       " '210',\n",
       " '23',\n",
       " '24',\n",
       " '24398',\n",
       " '243a',\n",
       " '279',\n",
       " '29',\n",
       " '2b',\n",
       " '2billion',\n",
       " '2x10',\n",
       " '300',\n",
       " '3000',\n",
       " '313327',\n",
       " '315',\n",
       " '322',\n",
       " '33',\n",
       " '33gxrf',\n",
       " '39',\n",
       " '390875584405933',\n",
       " '391725794320912',\n",
       " '40beuutvu2zkxk4utgpz8k',\n",
       " '4436607',\n",
       " '4604617',\n",
       " '48051',\n",
       " '484',\n",
       " '492',\n",
       " '4shared',\n",
       " '4snjqp',\n",
       " '4th',\n",
       " '50',\n",
       " '521',\n",
       " '5242575',\n",
       " '5277478',\n",
       " '5287',\n",
       " '57',\n",
       " '58',\n",
       " '5800',\n",
       " '5af506e1',\n",
       " '5c2f',\n",
       " '5million',\n",
       " '5s',\n",
       " '616375350',\n",
       " '636',\n",
       " '6381501',\n",
       " '694',\n",
       " '700',\n",
       " '733634264',\n",
       " '733949243353321',\n",
       " '734237113324534',\n",
       " '74',\n",
       " '750',\n",
       " '783',\n",
       " '79',\n",
       " '821',\n",
       " '884',\n",
       " '898',\n",
       " '8bit',\n",
       " '9082175',\n",
       " '9107',\n",
       " '9277547',\n",
       " '950',\n",
       " '969',\n",
       " '9bzkp7q19f0',\n",
       " '_0f9fa8aa',\n",
       " '__killuminati94',\n",
       " '_bzszz',\n",
       " '_chris_cz',\n",
       " '_fphgk5zllsvdqv0zuf0mb',\n",
       " '_gibu',\n",
       " '_o3h',\n",
       " '_ry6f57sprnd2xv',\n",
       " '_thqbeum69aqup1ih',\n",
       " '_trksid',\n",
       " '_vlczzrg8vgctlpsd9ongewhj8',\n",
       " 'aaaaaaa',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'absolutely',\n",
       " 'access',\n",
       " 'accessories',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'acn2g',\n",
       " 'acting',\n",
       " 'active',\n",
       " 'actor',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'adding',\n",
       " 'admit',\n",
       " 'adsense',\n",
       " 'advice',\n",
       " 'affiliateid',\n",
       " 'after',\n",
       " 'again',\n",
       " 'ago',\n",
       " 'ahhh',\n",
       " 'al',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allot',\n",
       " 'allow',\n",
       " 'allways',\n",
       " 'almond',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'alot',\n",
       " 'also',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'america',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'and',\n",
       " 'andrijamatf',\n",
       " 'android',\n",
       " 'angel',\n",
       " 'angry',\n",
       " 'animations',\n",
       " 'annoying',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyway',\n",
       " 'apocalypse',\n",
       " 'app',\n",
       " 'apparel',\n",
       " 'apparently',\n",
       " 'appreciate',\n",
       " 'apps',\n",
       " 'are',\n",
       " 'around',\n",
       " 'art',\n",
       " 'as',\n",
       " 'aseris',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'aspx',\n",
       " 'ass',\n",
       " 'at',\n",
       " 'attention',\n",
       " 'auburn',\n",
       " 'audiojungle',\n",
       " 'auditioning',\n",
       " 'avaaz',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'away',\n",
       " 'aways',\n",
       " 'awesome',\n",
       " 'awesomeness',\n",
       " 'b00ecvf93g',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'band',\n",
       " 'bass',\n",
       " 'bd3721315',\n",
       " 'be',\n",
       " 'beautiful',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'beibs',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'between',\n",
       " 'bf4',\n",
       " 'bieber',\n",
       " 'big',\n",
       " 'bighit',\n",
       " 'bilion',\n",
       " 'billion',\n",
       " 'billions',\n",
       " 'billon',\n",
       " 'binbox',\n",
       " 'bing',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'blanc',\n",
       " 'block',\n",
       " 'blue',\n",
       " 'bomb',\n",
       " 'book',\n",
       " 'bother',\n",
       " 'bots',\n",
       " 'bottom',\n",
       " 'bowl',\n",
       " 'boyfriend',\n",
       " 'boys',\n",
       " 'bps',\n",
       " 'br',\n",
       " 'brain',\n",
       " 'brand',\n",
       " 'brew',\n",
       " 'bringing',\n",
       " 'brother',\n",
       " 'brotherhood',\n",
       " 'brothers',\n",
       " 'brt0u5',\n",
       " 'bs',\n",
       " 'bubblews',\n",
       " 'bucket',\n",
       " 'burned',\n",
       " 'but',\n",
       " 'butalabs',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'c349',\n",
       " 'call',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'can',\n",
       " 'cant',\n",
       " 'capitalized',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'caroline',\n",
       " 'cash',\n",
       " 'cats',\n",
       " 'cd92db3f4',\n",
       " 'censor',\n",
       " 'certain',\n",
       " 'chacking',\n",
       " 'chainise',\n",
       " 'challenges',\n",
       " 'chance',\n",
       " 'chanel',\n",
       " 'change',\n",
       " 'chanicka',\n",
       " 'channel',\n",
       " 'channels',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'checking',\n",
       " 'chhanel',\n",
       " 'chick',\n",
       " 'child',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'ching',\n",
       " 'chiptunes',\n",
       " 'christmas',\n",
       " 'chubbz',\n",
       " 'chuck',\n",
       " 'cirus',\n",
       " 'citizen',\n",
       " 'cjfoftxeba',\n",
       " 'cleaning',\n",
       " 'click',\n",
       " 'clicked',\n",
       " 'clip',\n",
       " 'close',\n",
       " 'clothes',\n",
       " 'clothing',\n",
       " 'co',\n",
       " 'code',\n",
       " 'codes',\n",
       " 'codytolleson',\n",
       " 'college',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comentars',\n",
       " 'comes',\n",
       " 'coming',\n",
       " 'comment',\n",
       " 'comment_id',\n",
       " 'commenting',\n",
       " 'comments',\n",
       " 'commercial',\n",
       " 'company',\n",
       " 'complaining',\n",
       " 'completely',\n",
       " 'concerts',\n",
       " 'condition',\n",
       " 'confidence',\n",
       " 'confirmed',\n",
       " 'connected',\n",
       " 'constructive',\n",
       " 'content',\n",
       " 'cool',\n",
       " 'could',\n",
       " 'count',\n",
       " 'countries',\n",
       " 'cover',\n",
       " 'covers',\n",
       " 'craft',\n",
       " 'crap',\n",
       " 'crazy',\n",
       " 'crdits',\n",
       " 'crea',\n",
       " 'credit',\n",
       " 'crew',\n",
       " 'criticism',\n",
       " 'crop',\n",
       " 'cross',\n",
       " 'crowd',\n",
       " 'cs',\n",
       " 'csgo',\n",
       " 'curled',\n",
       " 'cute',\n",
       " 'cvhmklt',\n",
       " 'cxpzpgb',\n",
       " 'czfcxsn0jnq',\n",
       " 'da',\n",
       " 'daaaaaaaaaaannng',\n",
       " 'dad',\n",
       " 'dafuq',\n",
       " 'daily',\n",
       " 'dance',\n",
       " 'dances',\n",
       " 'dancing',\n",
       " 'day',\n",
       " 'dealing',\n",
       " 'dear',\n",
       " 'december',\n",
       " 'decent',\n",
       " 'dedicated',\n",
       " 'defuse',\n",
       " 'deserve',\n",
       " 'designs',\n",
       " 'details',\n",
       " 'dick',\n",
       " 'did',\n",
       " 'diddle',\n",
       " 'didn',\n",
       " 'die',\n",
       " 'difference',\n",
       " 'difficult',\n",
       " 'dinero',\n",
       " 'ding',\n",
       " 'direction',\n",
       " 'disappointed',\n",
       " 'discover',\n",
       " 'dislike',\n",
       " 'dislikes',\n",
       " 'dislikesssssssssssssssssssssssssssssssss',\n",
       " 'divertenti',\n",
       " 'diys',\n",
       " 'dizzy',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'doing',\n",
       " 'dolacz',\n",
       " 'dominate',\n",
       " 'don',\n",
       " 'donate',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'download',\n",
       " 'downloading',\n",
       " 'dresses',\n",
       " 'dressprettyonce',\n",
       " 'driving',\n",
       " 'drone',\n",
       " 'drones',\n",
       " 'drop',\n",
       " 'drugs',\n",
       " 'drunk',\n",
       " 'dubstep',\n",
       " 'dumb',\n",
       " 'dunno',\n",
       " 'during',\n",
       " 'duty',\n",
       " 'dylan',\n",
       " 'earn',\n",
       " 'earth',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'easypromosapp',\n",
       " 'ebay',\n",
       " 'ede05ea397ca',\n",
       " 'editor',\n",
       " 'edm',\n",
       " 'eeccon',\n",
       " 'effects',\n",
       " 'effort',\n",
       " 'ehi',\n",
       " 'ejw9kvkoxdamqm808h5z',\n",
       " 'elevator',\n",
       " 'eliminate',\n",
       " 'emerson_zanol',\n",
       " 'end',\n",
       " 'english',\n",
       " 'enimen',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'entertaining',\n",
       " 'entire',\n",
       " 'epic',\n",
       " 'equals',\n",
       " 'ermail',\n",
       " 'esteem',\n",
       " 'etc',\n",
       " 'eugenekalinin',\n",
       " 'eve',\n",
       " 'even',\n",
       " 'event',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyday',\n",
       " 'everyone',\n",
       " 'everyones',\n",
       " 'everything',\n",
       " 'ex',\n",
       " 'excuse',\n",
       " 'expectations',\n",
       " 'expensive',\n",
       " 'experiments',\n",
       " 'explore',\n",
       " 'exposure',\n",
       " 'eyebrows',\n",
       " 'eyes',\n",
       " 'f7',\n",
       " 'fablife',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'facts',\n",
       " 'fail',\n",
       " 'fake',\n",
       " 'family',\n",
       " 'fanboys',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fashionable',\n",
       " 'fb',\n",
       " 'featured',\n",
       " 'feedback',\n",
       " 'feel',\n",
       " 'festival',\n",
       " 'few',\n",
       " 'fighting',\n",
       " 'figure',\n",
       " 'find',\n",
       " 'fire',\n",
       " 'fireball',\n",
       " 'first',\n",
       " 'fish',\n",
       " 'flipagram',\n",
       " 'flute',\n",
       " 'fly',\n",
       " 'follow',\n",
       " 'follower',\n",
       " 'football',\n",
       " 'for',\n",
       " 'forget',\n",
       " 'foto',\n",
       " 'found',\n",
       " 'four',\n",
       " 'freddy',\n",
       " 'free',\n",
       " 'freemyapps',\n",
       " 'french',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'frigea',\n",
       " 'from',\n",
       " 'fruity',\n",
       " 'fuck',\n",
       " 'fucked',\n",
       " 'fucken',\n",
       " 'fucking',\n",
       " 'fudairyqueen',\n",
       " 'fuego',\n",
       " 'fun',\n",
       " 'funnier',\n",
       " 'funny',\n",
       " 'funnytortspics',\n",
       " 'future',\n",
       " 'gabriel',\n",
       " 'game',\n",
       " 'games',\n",
       " 'gamestop',\n",
       " 'gaming',\n",
       " 'ganga',\n",
       " 'gangam',\n",
       " 'gangman',\n",
       " 'gangnam',\n",
       " 'gangnamstyle',\n",
       " 'gatti',\n",
       " 'gay',\n",
       " 'gbphotographygb',\n",
       " 'gcmforex',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'ghost',\n",
       " 'gift',\n",
       " 'girl',\n",
       " 'girls',\n",
       " 'give',\n",
       " 'giveaways',\n",
       " 'giver',\n",
       " 'glasses',\n",
       " 'go',\n",
       " 'goal',\n",
       " 'goes',\n",
       " 'gofundme',\n",
       " 'going',\n",
       " 'gonna',\n",
       " 'good',\n",
       " 'goodbye',\n",
       " 'google',\n",
       " 'gook',\n",
       " 'got',\n",
       " 'gotta',\n",
       " 'gotten',\n",
       " 'government',\n",
       " 'gp',\n",
       " 'grateful',\n",
       " 'great',\n",
       " 'greetings',\n",
       " 'group',\n",
       " 'grow',\n",
       " 'grwmps',\n",
       " 'gt',\n",
       " 'gta5',\n",
       " 'guardalo',\n",
       " 'gun',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'gvr7xg',\n",
       " 'gwar',\n",
       " 'hacked',\n",
       " 'hackers',\n",
       " 'hackfbaccountlive',\n",
       " 'had',\n",
       " 'haha',\n",
       " 'hahah',\n",
       " 'hahahahah',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'halftime',\n",
       " 'halp',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'has',\n",
       " 'hassle',\n",
       " 'hate',\n",
       " 'haters',\n",
       " 'hav',\n",
       " 'have',\n",
       " 'having',\n",
       " 'he',\n",
       " 'head',\n",
       " 'headbutt',\n",
       " 'hear',\n",
       " 'heart',\n",
       " 'heck',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'high',\n",
       " 'him',\n",
       " 'hip',\n",
       " 'his',\n",
       " 'history',\n",
       " 'hit',\n",
       " 'hits',\n",
       " 'hl',\n",
       " 'hole',\n",
       " 'holy',\n",
       " 'hop',\n",
       " 'hope',\n",
       " 'hoppa',\n",
       " 'hour',\n",
       " 'how',\n",
       " 'html',\n",
       " 'http',\n",
       " 'https',\n",
       " 'huge',\n",
       " 'huh',\n",
       " 'humanity',\n",
       " 'hunger',\n",
       " 'hw',\n",
       " 'hwang',\n",
       " 'hyperurl',\n",
       " 'hyuna',\n",
       " 'ice',\n",
       " 'id',\n",
       " 'idea',\n",
       " 'ie',\n",
       " 'if',\n",
       " 'ig',\n",
       " 'il',\n",
       " 'ill',\n",
       " 'illuminati',\n",
       " 'im',\n",
       " 'image2you',\n",
       " 'imagine',\n",
       " 'improve',\n",
       " 'in',\n",
       " 'including',\n",
       " 'incmedia',\n",
       " 'indiegogo',\n",
       " 'inspired',\n",
       " 'instagram',\n",
       " 'instagraml',\n",
       " 'internet',\n",
       " 'into',\n",
       " 'inviting',\n",
       " 'io',\n",
       " 'iphone',\n",
       " 'iq2',\n",
       " 'irl',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'isnt',\n",
       " 'it',\n",
       " 'ithat',\n",
       " 'itm',\n",
       " 'its',\n",
       " 'itunes',\n",
       " 'itz',\n",
       " 'jackal',\n",
       " 'jackson',\n",
       " 'jae',\n",
       " 'james',\n",
       " 'jap',\n",
       " 'jaroadc',\n",
       " 'jb',\n",
       " 'jelly',\n",
       " 'jellyfish',\n",
       " 'jenny',\n",
       " 'job',\n",
       " 'join',\n",
       " 'joint2',\n",
       " 'joke',\n",
       " 'joking',\n",
       " 'jr',\n",
       " 'jtcjnmho',\n",
       " 'juice',\n",
       " 'julie',\n",
       " 'julien',\n",
       " 'juno',\n",
       " 'just',\n",
       " 'justin',\n",
       " 'juyk',\n",
       " 'jyp',\n",
       " 'k6a5xt',\n",
       " 'kamal',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'keyword',\n",
       " 'kickstarter',\n",
       " 'kids',\n",
       " 'kidsmediausa',\n",
       " 'kidz',\n",
       " 'kind',\n",
       " 'kinda',\n",
       " 'king',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'knows',\n",
       " 'kobyoshi02',\n",
       " 'kodysman',\n",
       " 'koean',\n",
       " 'kollektivet',\n",
       " 'korea',\n",
       " 'korean',\n",
       " 'koreans',\n",
       " 'kyle',\n",
       " 'l2649',\n",
       " 'l551h',\n",
       " 'la',\n",
       " 'lacked',\n",
       " 'lada',\n",
       " 'language',\n",
       " 'last',\n",
       " 'later',\n",
       " 'laugh',\n",
       " 'launchpad',\n",
       " 'lazy',\n",
       " 'leader',\n",
       " 'league',\n",
       " 'leah',\n",
       " 'learn',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'left',\n",
       " 'let',\n",
       " 'lets',\n",
       " 'lexis',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likes',\n",
       " 'liking',\n",
       " 'limit',\n",
       " 'ling',\n",
       " 'link',\n",
       " 'linkbucks',\n",
       " 'listen',\n",
       " 'listening',\n",
       " 'listing',\n",
       " 'lists',\n",
       " 'little',\n",
       " 'littlebrother',\n",
       " 'live',\n",
       " 'll',\n",
       " 'lnuj',\n",
       " 'lol',\n",
       " 'long',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'lool',\n",
       " 'loool',\n",
       " 'loops',\n",
       " 'lordviperas',\n",
       " 'lot',\n",
       " 'lots',\n",
       " 'love',\n",
       " 'loved',\n",
       " 'loving',\n",
       " 'low',\n",
       " 'lt',\n",
       " 'lucas',\n",
       " 'lucks',\n",
       " 'luka1qmrhf',\n",
       " 'luther',\n",
       " 'lyrics',\n",
       " 'm1555',\n",
       " 'mabey',\n",
       " 'made',\n",
       " 'make',\n",
       " 'making',\n",
       " 'man',\n",
       " 'management',\n",
       " 'many',\n",
       " 'mario',\n",
       " 'marius',\n",
       " 'market',\n",
       " 'marketglory',\n",
       " 'markusmairhofer',\n",
       " 'martin',\n",
       " 'mathster',\n",
       " 'may',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'mee',\n",
       " 'meets',\n",
       " 'members',\n",
       " 'memories',\n",
       " 'men',\n",
       " 'mercury',\n",
       " 'meselx',\n",
       " 'michael',\n",
       " 'miley',\n",
       " 'milions',\n",
       " 'million',\n",
       " 'millions',\n",
       " 'millioon',\n",
       " 'millisecond',\n",
       " 'millon',\n",
       " 'min',\n",
       " 'mind',\n",
       " 'mine',\n",
       " 'minecraft',\n",
       " 'minoo',\n",
       " 'minutes',\n",
       " 'miss',\n",
       " 'mix',\n",
       " 'model',\n",
       " 'mom',\n",
       " 'mon',\n",
       " 'money',\n",
       " 'monkey',\n",
       " 'monkeys',\n",
       " 'montages',\n",
       " 'month',\n",
       " 'months',\n",
       " 'more',\n",
       " 'morgage',\n",
       " 'moroccan',\n",
       " 'most',\n",
       " 'mother',\n",
       " 'moved',\n",
       " 'movie',\n",
       " 'mp3s',\n",
       " 'ms',\n",
       " 'mscalifornia95',\n",
       " 'msmarilynmiles',\n",
       " 'much',\n",
       " 'multiple',\n",
       " 'murdev',\n",
       " 'music',\n",
       " 'must',\n",
       " 'mute',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'nail',\n",
       " 'nails',\n",
       " 'name',\n",
       " 'national',\n",
       " 'necks',\n",
       " 'need',\n",
       " 'neon',\n",
       " 'net',\n",
       " 'network',\n",
       " 'never',\n",
       " 'new',\n",
       " 'newest',\n",
       " 'news',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'nicushorbboy',\n",
       " 'night',\n",
       " 'nike',\n",
       " 'ninja',\n",
       " 'no',\n",
       " 'non',\n",
       " 'norrus',\n",
       " 'not',\n",
       " 'notch',\n",
       " 'now',\n",
       " 'number',\n",
       " 'numbers',\n",
       " 'obsessed',\n",
       " 'odowd',\n",
       " 'of',\n",
       " 'off',\n",
       " 'offer',\n",
       " 'officialpsy',\n",
       " 'offset',\n",
       " 'offıcal',\n",
       " 'often',\n",
       " 'old',\n",
       " 'older',\n",
       " 'olds',\n",
       " 'oldspice',\n",
       " 'olp_tab_refurbished',\n",
       " 'omg',\n",
       " 'on',\n",
       " 'once',\n",
       " 'oncueapparel',\n",
       " 'one',\n",
       " 'only',\n",
       " 'oppa',\n",
       " 'or',\n",
       " 'org',\n",
       " 'other',\n",
       " 'our',\n",
       " 'out',\n",
       " 'outfit',\n",
       " 'ovbiously',\n",
       " 'over',\n",
       " 'own',\n",
       " 'p3984',\n",
       " 'page',\n",
       " 'pages',\n",
       " 'paid',\n",
       " 'pal',\n",
       " 'pan',\n",
       " 'pants',\n",
       " 'part',\n",
       " 'partners',\n",
       " 'party',\n",
       " 'passed',\n",
       " 'pause',\n",
       " 'pay',\n",
       " 'pazzi',\n",
       " 'pdf',\n",
       " 'pe',\n",
       " 'peace',\n",
       " 'penis',\n",
       " 'people',\n",
       " 'peoples',\n",
       " 'perfect',\n",
       " 'perform',\n",
       " 'permpage',\n",
       " 'person',\n",
       " 'petition',\n",
       " 'petitions',\n",
       " 'phenomena',\n",
       " 'photo',\n",
       " 'photos',\n",
       " 'php',\n",
       " 'pictures',\n",
       " 'piece',\n",
       " 'pivot',\n",
       " 'pl',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'planet',\n",
       " 'platform',\n",
       " 'play',\n",
       " 'please',\n",
       " 'plizz',\n",
       " 'pls',\n",
       " 'plus',\n",
       " 'plz',\n",
       " 'pnref',\n",
       " 'po',\n",
       " 'point',\n",
       " 'pop',\n",
       " 'popaegis',\n",
       " 'popular',\n",
       " 'population',\n",
       " 'populatoin',\n",
       " 'portfolio',\n",
       " 'post',\n",
       " 'posting',\n",
       " 'posts',\n",
       " 'pouring',\n",
       " 'pplease',\n",
       " 'pray',\n",
       " 'praying',\n",
       " 'prehistoric',\n",
       " 'premium',\n",
       " 'pretty',\n",
       " 'preview',\n",
       " 'pride',\n",
       " 'problem',\n",
       " 'prod',\n",
       " 'producer',\n",
       " 'project',\n",
       " 'projects',\n",
       " 'promise',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give the output of vectorizer.get_feature_names()\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It return the names of features from the dataset, the output begin with numbers and then words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "df_psy_shuffle = df_psy.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>z13qgx0yzwf1uj1xm04ccbkhjnrsgz0i41g</td>\n",
       "      <td>firo mota</td>\n",
       "      <td>2014-11-04T14:38:42</td>\n",
       "      <td>please subscribe i am a new youtuber and need ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>z13sh3cz1kbqgrai504cf53qsq25ypmi5zs0k</td>\n",
       "      <td>Leonel Hernandez</td>\n",
       "      <td>2014-11-14T12:35:38</td>\n",
       "      <td>Something to dance to, even if your sad JUST ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>z12ftpab5svihfffz23kf3iiymiwjzesi</td>\n",
       "      <td>trespasser4000</td>\n",
       "      <td>2014-11-04T22:07:22</td>\n",
       "      <td>This song never gets old love it.﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>z12qth5j0ob1fx3q404chvy4fz32tbkpllk0k</td>\n",
       "      <td>Tony K Frazier</td>\n",
       "      <td>2013-11-28T23:57:13</td>\n",
       "      <td>http://ubuntuone.com/40beUutVu2ZKxK4uTgPZ8K﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>z12cehoxozfgg3nok04cjj05xznbgrlpfjo</td>\n",
       "      <td>Elieo Cardiopulmonary</td>\n",
       "      <td>2014-11-08T15:29:52</td>\n",
       "      <td>im sorry for the spam but My name is Jenny. I ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>z123jlf4lzjbgpbcr23yhxyqbpe3gxpvm</td>\n",
       "      <td>TIGERIO_</td>\n",
       "      <td>2014-11-04T19:46:38</td>\n",
       "      <td>EHI GUYS CAN YOU SUBSCRIBE IN MY CHANNEL? I AM...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>z122f1fy5muwdxdxd04cexyxes3hh5hrifc</td>\n",
       "      <td>Squir3</td>\n",
       "      <td>2014-11-02T18:34:03</td>\n",
       "      <td>http://woobox.com/33gxrf/brt0u5 FREE CS GO!!!!﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>z12sjrqiurm3sd4rh04chz4oplrmhzmgzmg0k</td>\n",
       "      <td>Stronzo Chicheritr</td>\n",
       "      <td>2014-11-07T20:01:15</td>\n",
       "      <td>prehistoric song..has been﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>z13osluqrpefv1hd323idhejzxanc3ai004</td>\n",
       "      <td>Tyrek Sings</td>\n",
       "      <td>2014-11-05T22:50:02</td>\n",
       "      <td>CHECK MY CHANNEL OUT PLEASE. I DO SINGING COVERS﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>z13zjbvbeszjcvdsx22ww5cgcrydzlf5u04</td>\n",
       "      <td>ROB YSF</td>\n",
       "      <td>2014-11-06T09:15:12</td>\n",
       "      <td>reminds me of this song https://soundcloud.com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                COMMENT_ID                 AUTHOR  \\\n",
       "106    z13qgx0yzwf1uj1xm04ccbkhjnrsgz0i41g              firo mota   \n",
       "343  z13sh3cz1kbqgrai504cf53qsq25ypmi5zs0k       Leonel Hernandez   \n",
       "112      z12ftpab5svihfffz23kf3iiymiwjzesi         trespasser4000   \n",
       "18   z12qth5j0ob1fx3q404chvy4fz32tbkpllk0k         Tony K Frazier   \n",
       "303    z12cehoxozfgg3nok04cjj05xznbgrlpfjo  Elieo Cardiopulmonary   \n",
       "..                                     ...                    ...   \n",
       "110      z123jlf4lzjbgpbcr23yhxyqbpe3gxpvm               TIGERIO_   \n",
       "80     z122f1fy5muwdxdxd04cexyxes3hh5hrifc                 Squir3   \n",
       "224  z12sjrqiurm3sd4rh04chz4oplrmhzmgzmg0k     Stronzo Chicheritr   \n",
       "144    z13osluqrpefv1hd323idhejzxanc3ai004            Tyrek Sings   \n",
       "154    z13zjbvbeszjcvdsx22ww5cgcrydzlf5u04                ROB YSF   \n",
       "\n",
       "                    DATE                                            CONTENT  \\\n",
       "106  2014-11-04T14:38:42  please subscribe i am a new youtuber and need ...   \n",
       "343  2014-11-14T12:35:38   Something to dance to, even if your sad JUST ...   \n",
       "112  2014-11-04T22:07:22                 This song never gets old love it.﻿   \n",
       "18   2013-11-28T23:57:13       http://ubuntuone.com/40beUutVu2ZKxK4uTgPZ8K﻿   \n",
       "303  2014-11-08T15:29:52  im sorry for the spam but My name is Jenny. I ...   \n",
       "..                   ...                                                ...   \n",
       "110  2014-11-04T19:46:38  EHI GUYS CAN YOU SUBSCRIBE IN MY CHANNEL? I AM...   \n",
       "80   2014-11-02T18:34:03    http://woobox.com/33gxrf/brt0u5 FREE CS GO!!!!﻿   \n",
       "224  2014-11-07T20:01:15                        prehistoric song..has been﻿   \n",
       "144  2014-11-05T22:50:02  CHECK MY CHANNEL OUT PLEASE. I DO SINGING COVERS﻿   \n",
       "154  2014-11-06T09:15:12  reminds me of this song https://soundcloud.com...   \n",
       "\n",
       "     CLASS  \n",
       "106      1  \n",
       "343      0  \n",
       "112      0  \n",
       "18       1  \n",
       "303      1  \n",
       "..     ...  \n",
       "110      1  \n",
       "80       1  \n",
       "224      0  \n",
       "144      1  \n",
       "154      1  \n",
       "\n",
       "[350 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_psy_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and testing set\n",
    "# first 300 for training and remain for testing\n",
    "d_train = df_psy_shuffle.iloc[:300]\n",
    "d_test = df_psy_shuffle.iloc[300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your training and testing attributes BOW \n",
    "# using vectorizer.fit_transform\n",
    "d_train_att = vectorizer.fit_transform(d_train['CONTENT'])\n",
    "d_test_att =vectorizer.transform(d_test['CONTENT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<300x1274 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3759 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1274)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_test_att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing labels\n",
    "d_train_label = d_train['CLASS']\n",
    "d_test_label = d_test['CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<300x1274 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3759 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train_att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d_train_att is a 300x1238 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50x1274 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 450 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_test_att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d_test_att is a 50x400 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=80)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=80)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=80)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create random forest classifier with 80 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=80)\n",
    "clf.fit(d_train_att, d_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(d_test_att, d_test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score for random forest classifier test set is 94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix for the test labels and prediction labels, and output array\n",
    "predicted_labels = clf.predict(d_test_att)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(d_test_label, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  0],\n",
       "       [ 4, 22]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest accuracy:  0.96 (+/-  0.0686 )\n"
     ]
    }
   ],
   "source": [
    "# Cross validate and output your accuracy\n",
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(clf,d_train_att, d_train_label, cv=5)\n",
    "\n",
    "print('Random forest accuracy: ', round(score.mean(), 4), '(+/- ', round(score.std()*2, 4),')')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation split our dataset into multiple portions. Some will use for training rest will use on testing. For example in above cross validation, we divide dataset in 5 portion. For 1 interation, first portion will use for test and rest will use for train. Then, for interation 2, second portion will use for test and rest will use for train. Repeat until all portion have been used for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concatenate all 5 comments file\n",
    "concat = [pd.read_csv('Youtube01-Psy.csv'), \n",
    "          pd.read_csv('Youtube02-KatyPerry.csv'), \n",
    "          pd.read_csv('Youtube03-LMFAO.csv'), \n",
    "          pd.read_csv('Youtube04-Eminem.csv'), \n",
    "          pd.read_csv('Youtube05-Shakira.csv')]\n",
    "combined_csv = pd.concat(concat, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>_2viQ_Qnc6-bMSjqyL1NKj57ROicCSJV5SwTrw-RFFA</td>\n",
       "      <td>Katie Mettam</td>\n",
       "      <td>2013-07-13T13:27:39.441000</td>\n",
       "      <td>I love this song because we sing it at Camp al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>_2viQ_Qnc6-pY-1yR6K2FhmC5i48-WuNx5CumlHLDAI</td>\n",
       "      <td>Sabina Pearson-Smith</td>\n",
       "      <td>2013-07-13T13:14:30.021000</td>\n",
       "      <td>I love this song for two reasons: 1.it is abou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>_2viQ_Qnc6_k_n_Bse9zVhJP8tJReZpo8uM2uZfnzDs</td>\n",
       "      <td>jeffrey jules</td>\n",
       "      <td>2013-07-13T12:09:31.188000</td>\n",
       "      <td>wow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>_2viQ_Qnc6_yBt8UGMWyg3vh0PulTqcqyQtdE7d4Fl0</td>\n",
       "      <td>Aishlin Maciel</td>\n",
       "      <td>2013-07-13T11:17:52.308000</td>\n",
       "      <td>Shakira u are so wiredo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>_2viQ_Qnc685RPw1aSa1tfrIuHXRvAQ2rPT9R06KTqA</td>\n",
       "      <td>Latin Bosch</td>\n",
       "      <td>2013-07-12T22:33:27.916000</td>\n",
       "      <td>Shakira is the best dancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1956 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       COMMENT_ID                AUTHOR  \\\n",
       "0     LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU             Julius NM   \n",
       "1     LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A           adam riyati   \n",
       "2     LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8      Evgeny Murashkin   \n",
       "3             z13jhp0bxqncu512g22wvzkasxmvvzjaz04       ElNino Melendez   \n",
       "4             z13fwbwp1oujthgqj04chlngpvzmtt3r3dw                GsMega   \n",
       "...                                           ...                   ...   \n",
       "1951  _2viQ_Qnc6-bMSjqyL1NKj57ROicCSJV5SwTrw-RFFA          Katie Mettam   \n",
       "1952  _2viQ_Qnc6-pY-1yR6K2FhmC5i48-WuNx5CumlHLDAI  Sabina Pearson-Smith   \n",
       "1953  _2viQ_Qnc6_k_n_Bse9zVhJP8tJReZpo8uM2uZfnzDs         jeffrey jules   \n",
       "1954  _2viQ_Qnc6_yBt8UGMWyg3vh0PulTqcqyQtdE7d4Fl0        Aishlin Maciel   \n",
       "1955  _2viQ_Qnc685RPw1aSa1tfrIuHXRvAQ2rPT9R06KTqA           Latin Bosch   \n",
       "\n",
       "                            DATE  \\\n",
       "0            2013-11-07T06:20:48   \n",
       "1            2013-11-07T12:37:15   \n",
       "2            2013-11-08T17:34:21   \n",
       "3            2013-11-09T08:28:43   \n",
       "4            2013-11-10T16:05:38   \n",
       "...                          ...   \n",
       "1951  2013-07-13T13:27:39.441000   \n",
       "1952  2013-07-13T13:14:30.021000   \n",
       "1953  2013-07-13T12:09:31.188000   \n",
       "1954  2013-07-13T11:17:52.308000   \n",
       "1955  2013-07-12T22:33:27.916000   \n",
       "\n",
       "                                                CONTENT  CLASS  \n",
       "0     Huh, anyway check out this you[tube] channel: ...      1  \n",
       "1     Hey guys check out my new channel and our firs...      1  \n",
       "2                just for test I have to say murdev.com      1  \n",
       "3      me shaking my sexy ass on my channel enjoy ^_^ ﻿      1  \n",
       "4               watch?v=vtaRGgvGtWQ   Check this out .﻿      1  \n",
       "...                                                 ...    ...  \n",
       "1951  I love this song because we sing it at Camp al...      0  \n",
       "1952  I love this song for two reasons: 1.it is abou...      0  \n",
       "1953                                                wow      0  \n",
       "1954                            Shakira u are so wiredo      0  \n",
       "1955                         Shakira is the best dancer      0  \n",
       "\n",
       "[1956 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght file:  1956\n",
      "Lenght of spam:  1005\n",
      "Lenght of non spam:  951\n"
     ]
    }
   ],
   "source": [
    "# Display the length of the file as well as the breakdown into spam and non-spam\n",
    "print('Lenght file: ', len(combined_csv))\n",
    "print('Lenght of spam: ', len(combined_csv[combined_csv.CLASS == 1]))\n",
    "print('Lenght of non spam: ', len(combined_csv[combined_csv.CLASS == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the new data, and create content and label sets, d_content, and d_label\n",
    "combined_df = combined_csv.sample(frac=1)\n",
    "d_content = combined_df['CONTENT']\n",
    "d_label = combined_df['CLASS']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage to use pipeline can minmal code and less room for mistake, instead using fit and transform method, programmer only need to use fit in pipline and make the code easler to read.\n",
    "\n",
    "Reference: <br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html<br>\n",
    "https://medium.com/mlearning-ai/how-to-use-sklearns-pipelines-to-optimize-your-analysis-b6cd91999be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mport both Pipeline and make_pipeline from sklearn\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipeline = Pipeline([('bag-of-words', CountVectorizer()),\n",
    "                     ('random forest', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;bag-of-words&#x27;, CountVectorizer()),\n",
       "                (&#x27;random forest&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;bag-of-words&#x27;, CountVectorizer()),\n",
       "                (&#x27;random forest&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('bag-of-words', CountVectorizer()),\n",
       "                ('random forest', RandomForestClassifier())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output the pipeline\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;bag-of-words&#x27;, CountVectorizer()),\n",
       "                (&#x27;random forest&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;bag-of-words&#x27;, CountVectorizer()),\n",
       "                (&#x27;random forest&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('bag-of-words', CountVectorizer()),\n",
       "                ('random forest', RandomForestClassifier())])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit your pipeline with the first 1500 entries of the content and the labels. Output.\n",
    "pipeline.fit(d_content[:1500], d_label[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use .score to score your pipeline\n",
    "pipeline.score(d_content[1500:], d_label[1500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use pipeline to predict spam or not\n",
    "pipeline.predict([\"what a neat video!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use pipeline to predict spam or not\n",
    "pipeline.predict([\"plz subscribe to my channel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For \"what a neat video!\", the model predict is 0, it mean not a spam.<br> \n",
    "For \"plz subscribe to my channel\", model predict is 1, it mean the comment is spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate pipeline using d_content and d_labels. Set cv=5\n",
    "scores = cross_val_score(pipeline, d_content, d_label, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accracy: 0.96 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "# Print out the accuracy(scores.mean) +/- 2sd\n",
    "print('Accracy: %0.2f (+/- %0.2f)' % (scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create second pipeline named pipeline2 which incorporates the TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "pipeline2 = make_pipeline(CountVectorizer(), TfidfTransformer(norm=None), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accracy: 0.96 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "# Cross validate pipeline2 using d_content and d_labels.\n",
    "# Output the accuracy(scores.mean) +/- 2sd. Set cv=5\n",
    "scores = cross_val_score(pipeline2, d_content, d_label)\n",
    "print('Accracy: %0.2f (+/- %0.2f)' % (scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countvectorizer', CountVectorizer()),\n",
       " ('tfidftransformer', TfidfTransformer(norm=None)),\n",
       " ('randomforestclassifier', RandomForestClassifier())]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Output the steps of pipeline2\n",
    "pipeline2.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter search\n",
    "parameters = {\n",
    "    'countvectorizer__max_features': (None, 1000, 2000),\n",
    "    'countvectorizer__ngram_range': ((1,1), (1,2)), # unigrams or bigrams\n",
    "    'countvectorizer__stop_words': ('english', None),\n",
    "    'tfidftransformer__use_idf': (True, False), # effectively turn on/off tfidf\n",
    "    'randomforestclassifier__n_estimators': (20, 59, 100)\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline2, parameters, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in part a use grid search to optimize the parameters, parameter can have 1000, to 2000 words. Using ngrams we can use single words, pairs of words.\n",
    "Use the English stop words or not. TF-IDF, on or off and random forest classifier uses 20,50 or 100 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;tfidftransformer&#x27;,\n",
       "                                        TfidfTransformer(norm=None)),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;countvectorizer__max_features&#x27;: (None, 1000, 2000),\n",
       "                         &#x27;countvectorizer__ngram_range&#x27;: ((1, 1), (1, 2)),\n",
       "                         &#x27;countvectorizer__stop_words&#x27;: (&#x27;english&#x27;, None),\n",
       "                         &#x27;randomforestclassifier__n_estimators&#x27;: (20, 59, 100),\n",
       "                         &#x27;tfidftransformer__use_idf&#x27;: (True, False)},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;tfidftransformer&#x27;,\n",
       "                                        TfidfTransformer(norm=None)),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;countvectorizer__max_features&#x27;: (None, 1000, 2000),\n",
       "                         &#x27;countvectorizer__ngram_range&#x27;: ((1, 1), (1, 2)),\n",
       "                         &#x27;countvectorizer__stop_words&#x27;: (&#x27;english&#x27;, None),\n",
       "                         &#x27;randomforestclassifier__n_estimators&#x27;: (20, 59, 100),\n",
       "                         &#x27;tfidftransformer__use_idf&#x27;: (True, False)},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;tfidftransformer&#x27;, TfidfTransformer(norm=None)),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer(norm=None)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                                       ('tfidftransformer',\n",
       "                                        TfidfTransformer(norm=None)),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'countvectorizer__max_features': (None, 1000, 2000),\n",
       "                         'countvectorizer__ngram_range': ((1, 1), (1, 2)),\n",
       "                         'countvectorizer__stop_words': ('english', None),\n",
       "                         'randomforestclassifier__n_estimators': (20, 59, 100),\n",
       "                         'tfidftransformer__use_idf': (True, False)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using .fit and d_content, and d_labels, perform the grid search\n",
    "grid_search.fit(d_content, d_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.959 \n",
      "Best parameters set: \n",
      "\t countvectorizer__max_features : None\n",
      "\t countvectorizer__ngram_range : (1, 2)\n",
      "\t countvectorizer__stop_words : None\n",
      "\t randomforestclassifier__n_estimators : 59\n",
      "\t tfidftransformer__use_idf : True\n"
     ]
    }
   ],
   "source": [
    "print('Best score: %0.3f ' % grid_search.best_score_)\n",
    "print('Best parameters set: ')\n",
    "for x in grid_search.best_params_:\n",
    "    print ('\\t', x ,':', grid_search.best_params_[x])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this output our best score was 0.960; with 2000 words, only pair of words, using english stop words; 100 trees, without TF-IDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "6043bf48e287341e9ba37f2e324016a0b261af4a2c78f092ae66eea75d2af0cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
